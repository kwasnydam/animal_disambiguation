{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Throughout the development I will assume, that the data coming from the 'animal' wiki pages true label animal and the one coming from 'device' true label is 'device'. It is not always true, but at this stage of development I consider manual labelling as too resource consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, 'data')\n",
    "RAW_DATA_PATH = os.path.join(DATA_PATH, 'raw')\n",
    "\n",
    "ENCODING = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data source, we will use wikipedia, because:\n",
    "    * It contains a fair amount of articles about both animal and computer device context of mouse\n",
    "    * It has a well defined API so we can write a script that automatically downloads the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal context\n",
    "animal_article_titles = ['mouse', 'kangaroo mouse', 'hopping mouse']\n",
    "for title in animal_article_titles:\n",
    "    save_path = os.path.join(RAW_DATA_PATH, 'animal', '{}.txt'.format(title))\n",
    "    raw = wikipedia.page(title).content\n",
    "    with codecs.open(save_path, 'w', ENCODING) as ofile:\n",
    "        ofile.write(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device context\n",
    "computer_device_article_titles = ['computer mouse', 'optical mouse']\n",
    "for title in computer_device_article_titles:\n",
    "    save_path = os.path.join(RAW_DATA_PATH, 'device', '{}.txt'.format(title))\n",
    "    raw = wikipedia.page(title).content\n",
    "    with codecs.open(save_path, 'w', ENCODING) as ofile:\n",
    "        ofile.write(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check that our data got downloaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'mouse'\n",
    "filepath = os.path.join(RAW_DATA_PATH, 'animal', '{}.txt'.format(title))\n",
    "with codecs.open(filepath, 'r', ENCODING) as rf:\n",
    "    assert rf.read() == wikipedia.page(title).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this, we have our raw data downloaded. Now we have to filter out sentences not containing \"mouse\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
